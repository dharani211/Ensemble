Here, we integrated NdLinear—a next-generation structure-preserving linear transformation layer—into three models and compared its performance against baseline nn.Linear layers. We applied NdLinear in a Vision Transformer (ViT) for image classification on CIFAR-10 images, an MLP for tabular data classification on the UCI Breast Cancer dataset, and a BERT text classifier for sentiment analysis. By replacing dense layers with ordinary architectures with NdLinear, we preserved the original multidimensional structure of the data, resulting in substantial decreases in parameters, more smooth training curves, and sometimes improved performance on tasks.

The experimental results indicate that the NdLinear-enhanced ViT enjoys higher validation accuracy with lower parameters, confirming its superiority in processing structure image data. Similarly, the NdLinear-based MLP successfully captures relation between features in tabular data with predictive consistency. In NLP applications, the NdLinear-adjusted BERT classifier presents balanced predictions and better convergence characteristics. In general, these benchmarks verify that employing NdLinear is an efficient and novel approach to enhancing model performance and efficiency, which is precisely in line with our project objectives.
